{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "df = pd.read_csv(\"valuation_forecasting/dataset_normalized.csv\")\n",
    "total_rows = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#splitting the dataset into train, validation and test set (70%, 10%, 20%)\n",
    "val_end = int(total_rows*0.8)\n",
    "\n",
    "labels = df[\"market_value\"].values\n",
    "df = df.drop(columns=[\"market_value\"])\n",
    "\n",
    "to_encode = df[['citizenship', 'current_club_id', 'position', 'sub_position', \"competitions_id\", \"clubs_id\"]]\n",
    "#to_encode = df[['citizenship', 'current_club_id', 'position', 'sub_position']]\n",
    "df = df.drop(['citizenship', 'current_club_id', 'position', 'sub_position', \"competitions_id\", \"clubs_id\"], axis=1)\n",
    "\n",
    "test_to_encode = to_encode.iloc[val_end:].values\n",
    "\n",
    "test_set = df.iloc[val_end:].values\n",
    "\n",
    "y_test = labels[val_end:]\n",
    "\n",
    "test_set_len = test_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input parameters\n",
    "num_input_size = test_set.shape[1]\n",
    "cat_input_size = to_encode.shape[1]\n",
    "total_input_size = num_input_size + cat_input_size\n",
    "voc_size_citizenship = len(to_encode['citizenship'].unique())\n",
    "voc_size_current_club_id = len(to_encode['current_club_id'].unique())\n",
    "voc_size_position = len(to_encode['position'].unique())\n",
    "voc_size_sub_position = len(to_encode['sub_position'].unique())\n",
    "voc_size_competitions = len(to_encode['competitions_id'].unique())\n",
    "voc_size_clubs = len(to_encode['clubs_id'].unique())\n",
    "#print them all\n",
    "print(\"input size of numerical features is: {}\".format(num_input_size))\n",
    "print(\"input size of categorical features is: {}\".format(cat_input_size))\n",
    "print(\"voc size citizenship is: {}\".format(voc_size_citizenship))\n",
    "print(\"voc size current club id is: {}\".format(voc_size_current_club_id))\n",
    "print(\"voc size position is: {}\".format(voc_size_position))\n",
    "print(\"voc size sub position is: {}\".format(voc_size_sub_position))\n",
    "print(\"voc size competitions is: {}\".format(voc_size_competitions))\n",
    "print(\"voc size clubs is: {}\".format(voc_size_clubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x, to_encode, y, length):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "\n",
    "        self.length = length\n",
    "        self.to_encode = torch.tensor(to_encode, device=device, dtype=torch.int32)\n",
    "        self.y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "        self.x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.to_encode[i] ,self.y[i]\n",
    "\n",
    "dataset_test = Dataset(test_set, test_to_encode, y_test, test_set_len)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a multilayer perceptron model class that inherits from nn.Module\n",
    "class MLP(nn.Module):\n",
    "  # Define the constructor method that takes the input size and the vocabulary sizes of four categorical features as arguments\n",
    "  def __init__(self, num_input_size, voc_size_citizenship, voc_size_current_club_id, voc_size_position, voc_size_sub_position, voc_size_competitions, voc_size_clubs, hidden_size1, hidden_size2, hidden_size3, dropout, device):\n",
    "    # Call the parent constructor\n",
    "    super(MLP, self).__init__()\n",
    "\n",
    "    # Compute the embedding sizes for each categorical feature using the fourth root of the vocabulary size\n",
    "    emb_size_citizenship = int(voc_size_citizenship ** (1/4))\n",
    "    emb_size_current_club_id = int(voc_size_current_club_id ** (1/4))\n",
    "    emb_size_position = int(voc_size_position ** (1/4))\n",
    "    emb_size_sub_position = int(voc_size_sub_position ** (1/4))\n",
    "    emb_size_competitions = int(voc_size_competitions ** (1/4))\n",
    "    emb_size_clubs = int(voc_size_clubs ** (1/4))\n",
    "\n",
    "    # Define embedding layers for each categorical feature using the computed embedding sizes\n",
    "    self.emb_cit = nn.Embedding(voc_size_citizenship, emb_size_citizenship, device=device)\n",
    "    self.emb_club = nn.Embedding(voc_size_current_club_id, emb_size_current_club_id, device=device)\n",
    "    self.emb_pos = nn.Embedding(voc_size_position, emb_size_position,  device=device)\n",
    "    self.emb_sub_pos = nn.Embedding(voc_size_sub_position, emb_size_sub_position, device=device)\n",
    "    self.emb_comp = nn.Embedding(voc_size_competitions, emb_size_competitions, device=device)\n",
    "    self.emb_clubs = nn.Embedding(voc_size_clubs, emb_size_clubs, device=device)\n",
    "\n",
    "    # Compute the total input size by adding the input size and the embedding sizes\n",
    "    total_input_size = num_input_size + emb_size_citizenship + emb_size_current_club_id + emb_size_position + emb_size_sub_position + emb_size_competitions + emb_size_clubs\n",
    "\n",
    "    # Define a linear layer that takes the total input size and outputs a single value\n",
    "    self.fc1 = nn.Linear(total_input_size, hidden_size1, device=device)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.batchnorm1 = nn.BatchNorm1d(hidden_size1, device=device)\n",
    "    self.fc2 = nn.Linear(hidden_size1, hidden_size2, device=device)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(hidden_size2, device=device)\n",
    "    self.fc3 = nn.Linear(hidden_size2, hidden_size3, device=device)\n",
    "    self.batchnorm3 = nn.BatchNorm1d(hidden_size3, device=device)\n",
    "    self.fc4 = nn.Linear(hidden_size3, 1, device=device)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  # Define the forward method that takes the numerical input and the categorical features to encode as arguments\n",
    "  def forward(self, x, to_encode):\n",
    "    # x: a tensor of shape (batch_size, input_size) containing the numerical features\n",
    "    # to_encode: a tensor of shape (batch_size, 4) containing the values of the categorical features\n",
    "\n",
    "    # Get the embeddings for each categorical feature using the corresponding embedding layer and indexing by the feature values\n",
    "    cit_emb = self.emb_cit(to_encode[:, 0])\n",
    "\n",
    "    club_emb = self.emb_club(to_encode[:, 1])\n",
    "\n",
    "    pos_emb = self.emb_pos(to_encode[:, 2])\n",
    "\n",
    "    sub_pos_emb = self.emb_sub_pos(to_encode[:, 3])\n",
    "\n",
    "    comp_emb = self.emb_comp(to_encode[:, 4])\n",
    "\n",
    "    clubs_emb = self.emb_clubs(to_encode[:, 5])\n",
    "\n",
    "    # Concatenate the numerical input and the embeddings along the second dimension\n",
    "    x = torch.cat((x, cit_emb, club_emb, pos_emb, sub_pos_emb, comp_emb, clubs_emb), dim=1)\n",
    "\n",
    "    # Apply the linear layers, dropout and batchnorm to get the output\n",
    "    x = self.fc1(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.batchnorm1(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    x = self.fc2(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.batchnorm2(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    x = self.fc3(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.batchnorm3(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    output = self.fc4(x)\n",
    "\n",
    "    # Return the output\n",
    "    return output.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a linear regression model class that inherits from nn.Module\n",
    "class LinearRegression(nn.Module):\n",
    "  # Define the constructor method that takes the input size and the vocabulary sizes of four categorical features as arguments\n",
    "  def __init__(self, num_input_size, voc_size_citizenship, voc_size_current_club_id, voc_size_position, voc_size_sub_position, voc_size_competitions, voc_size_clubs, device):\n",
    "    # Call the parent constructor\n",
    "    super(LinearRegression, self).__init__()\n",
    "\n",
    "    # Compute the embedding sizes for each categorical feature using the fourth root of the vocabulary size\n",
    "    emb_size_citizenship = int(voc_size_citizenship ** (1/4))\n",
    "    emb_size_current_club_id = int(voc_size_current_club_id ** (1/4))\n",
    "    emb_size_position = int(voc_size_position ** (1/4))\n",
    "    emb_size_sub_position = int(voc_size_sub_position ** (1/4))\n",
    "    emb_size_competitions = int(voc_size_competitions ** (1/4))\n",
    "    emb_size_clubs = int(voc_size_clubs ** (1/4))\n",
    "\n",
    "    # Define embedding layers for each categorical feature using the computed embedding sizes\n",
    "    self.emb_cit = nn.Embedding(voc_size_citizenship, emb_size_citizenship, device=device)\n",
    "    self.emb_club = nn.Embedding(voc_size_current_club_id, emb_size_current_club_id, device=device)\n",
    "    self.emb_pos = nn.Embedding(voc_size_position, emb_size_position,  device=device)\n",
    "    self.emb_sub_pos = nn.Embedding(voc_size_sub_position, emb_size_sub_position, device=device)\n",
    "    self.emb_comp = nn.Embedding(voc_size_competitions, emb_size_competitions, device=device)\n",
    "    self.emb_clubs = nn.Embedding(voc_size_clubs, emb_size_clubs, device=device)\n",
    "\n",
    "    # Compute the total input size by adding the input size and the embedding sizes\n",
    "    total_input_size = num_input_size + emb_size_citizenship + emb_size_current_club_id + emb_size_position + emb_size_sub_position + emb_size_competitions + emb_size_clubs\n",
    "\n",
    "    # Define a linear layer that takes the total input size and outputs a single value\n",
    "    self.fc1 = nn.Linear(total_input_size, 1, device=device)\n",
    "\n",
    "  # Define the forward method that takes the numerical input and the categorical features to encode as arguments\n",
    "  def forward(self, x, to_encode):\n",
    "    # x: a tensor of shape (batch_size, num_input_size) containing the numerical features\n",
    "    # to_encode: a tensor of shape (batch_size, 4) containing the values of the categorical features\n",
    "\n",
    "    # Get the embeddings for each categorical feature using the corresponding embedding layer and indexing by the feature values\n",
    "    cit_emb = self.emb_cit(to_encode[:, 0])\n",
    "\n",
    "    club_emb = self.emb_club(to_encode[:, 1])\n",
    "\n",
    "    pos_emb = self.emb_pos(to_encode[:, 2])\n",
    "\n",
    "    sub_pos_emb = self.emb_sub_pos(to_encode[:, 3])\n",
    "\n",
    "    comp_emb = self.emb_comp(to_encode[:, 4])\n",
    "\n",
    "    clubs_emb = self.emb_clubs(to_encode[:, 5])\n",
    "\n",
    "    # Concatenate the numerical input and the embeddings along the second dimension\n",
    "    x = torch.cat((x, cit_emb, club_emb, pos_emb, sub_pos_emb, comp_emb, clubs_emb), dim=1)\n",
    "\n",
    "    # Apply the linear layer to get the output\n",
    "    output = self.fc1(x)\n",
    "\n",
    "    # Return the output\n",
    "    return output.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a LSTM model class that inherits from nn.Module\n",
    "class LSTM(nn.Module):\n",
    "  # Define the constructor method that takes the input size and the vocabulary sizes of four categorical features as arguments\n",
    "  def __init__(self, num_input_size, voc_size_citizenship, voc_size_current_club_id, voc_size_position, voc_size_sub_position, voc_size_competitions, voc_size_clubs, hidden_size1, num_layers, dropout, device):\n",
    "    # Call the parent constructor\n",
    "    super(LSTM, self).__init__()\n",
    "\n",
    "    # Compute the embedding sizes for each categorical feature using the fourth root of the vocabulary size\n",
    "    emb_size_citizenship = int(voc_size_citizenship ** (1/4))\n",
    "    emb_size_current_club_id = int(voc_size_current_club_id ** (1/4))\n",
    "    emb_size_position = int(voc_size_position ** (1/4))\n",
    "    emb_size_sub_position = int(voc_size_sub_position ** (1/4))\n",
    "    emb_size_competitions = int(voc_size_competitions ** (1/4))\n",
    "    emb_size_clubs = int(voc_size_clubs ** (1/4))\n",
    "\n",
    "    # Define embedding layers for each categorical feature using the computed embedding sizes\n",
    "    self.emb_cit = nn.Embedding(voc_size_citizenship, emb_size_citizenship, device=device)\n",
    "    self.emb_club = nn.Embedding(voc_size_current_club_id, emb_size_current_club_id, device=device)\n",
    "    self.emb_pos = nn.Embedding(voc_size_position, emb_size_position,  device=device)\n",
    "    self.emb_sub_pos = nn.Embedding(voc_size_sub_position, emb_size_sub_position, device=device)\n",
    "    self.emb_comp = nn.Embedding(voc_size_competitions, emb_size_competitions, device=device)\n",
    "    self.emb_clubs = nn.Embedding(voc_size_clubs, emb_size_clubs, device=device)\n",
    "\n",
    "    # Compute the total input size by adding the input size and the embedding sizes\n",
    "    total_input_size = num_input_size + emb_size_citizenship + emb_size_current_club_id + emb_size_position + emb_size_sub_position + emb_size_competitions + emb_size_clubs\n",
    "\n",
    "    self.lstm1 = nn.LSTM(total_input_size, hidden_size1, num_layers=num_layers, batch_first=True, dropout=dropout, device=device)\n",
    "\n",
    "    # Define a linear layer that takes the total input size and outputs a single value\n",
    "    self.fc1 = nn.Linear(hidden_size1, 1, device=device)\n",
    "\n",
    "\n",
    "\n",
    "  # Define the forward method that takes the numerical input and the categorical features to encode as arguments\n",
    "  def forward(self, x, to_encode):\n",
    "    # x: a tensor of shape (batch_size, num_input_size) containing the numerical features\n",
    "    # to_encode: a tensor of shape (batch_size, 4) containing the values of the categorical features\n",
    "\n",
    "    # Get the embeddings for each categorical feature using the corresponding embedding layer and indexing by the feature values\n",
    "    cit_emb = self.emb_cit(to_encode[:, 0])\n",
    "\n",
    "    club_emb = self.emb_club(to_encode[:, 1])\n",
    "\n",
    "    pos_emb = self.emb_pos(to_encode[:, 2])\n",
    "\n",
    "    sub_pos_emb = self.emb_sub_pos(to_encode[:, 3])\n",
    "\n",
    "    comp_emb = self.emb_comp(to_encode[:, 4])\n",
    "\n",
    "    clubs_emb = self.emb_clubs(to_encode[:, 5])\n",
    "\n",
    "    # Concatenate the numerical input and the embeddings along the second dimension\n",
    "    x = torch.cat((x, cit_emb, club_emb, pos_emb, sub_pos_emb, comp_emb, clubs_emb), dim=1)\n",
    "\n",
    "    # Add a dimension to the numerical input tensor corresponding to the sequence length\n",
    "    x = x[:, None, :]\n",
    "\n",
    "    # Apply the linear layer to get the output\n",
    "    out1, (h1, c1) = self.lstm1(x)\n",
    "    output = self.fc1(h1[0])\n",
    "\n",
    "    # Return the output\n",
    "    return output.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLP(num_input_size, voc_size_citizenship, voc_size_current_club_id, voc_size_position, voc_size_sub_position, voc_size_competitions, voc_size_clubs, hidden_size1=176, hidden_size2=64, hidden_size3=16, dropout=0.2, device=device)\n",
    "mlp.load_state_dict(torch.load(\"models/best_mlp.pth\"))\n",
    "mlp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = LSTM(num_input_size, voc_size_citizenship, voc_size_current_club_id, voc_size_position, voc_size_sub_position, voc_size_competitions, voc_size_clubs, hidden_size1=32, num_layers=2, dropout=0.2, device=device)\n",
    "lstm.load_state_dict(torch.load(\"models/best_lstm.pth\"))\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear = LinearRegression(num_input_size, voc_size_citizenship, voc_size_current_club_id, voc_size_position, voc_size_sub_position, voc_size_competitions, voc_size_clubs, device=device)\n",
    "linear.load_state_dict(torch.load(\"models/best_linear.pth\"))\n",
    "linear.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagging = pickle.load(open(\"models/best_bagging\", 'rb'))\n",
    "\n",
    "gbr = pickle.load(open(\"models/best_gbr\", 'rb'))\n",
    "\n",
    "rf = pickle.load(open(\"models/best_rf\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_predictions = []\n",
    "lstm_predictions = []\n",
    "linear_predictions = []\n",
    "all_predictions = []\n",
    "all_targets = y_test\n",
    "\n",
    "for inputs, to_encode, targets in test_loader:\n",
    "  mlp_predictions.append(mlp(inputs, to_encode).detach().cpu().numpy()[0])\n",
    "  lstm_predictions.append(lstm(inputs, to_encode).detach().cpu().numpy()[0])\n",
    "  linear_predictions.append(linear(inputs, to_encode).detach().cpu().numpy()[0])\n",
    "\n",
    "all_predictions.append(mlp_predictions)\n",
    "all_predictions.append(lstm_predictions)\n",
    "all_predictions.append(linear_predictions)\n",
    "\n",
    "x_test = np.concatenate((test_to_encode, test_set), axis=1)\n",
    "all_predictions.append(bagging.predict(x_test))\n",
    "all_predictions.append(gbr.predict(x_test))\n",
    "all_predictions.append(rf.predict(x_test))\n",
    "\n",
    "r2score = []\n",
    "mse = []\n",
    "rmse = []\n",
    "mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_predictions)):\n",
    "  r2score.append(r2_score(all_targets, all_predictions[i]))\n",
    "  mse.append(mean_squared_error(all_targets, all_predictions[i]))\n",
    "  rmse.append(np.sqrt(mse[i]))\n",
    "  mae.append(mean_absolute_error(all_targets, all_predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = ['MLP', 'LSTM', 'Linear', 'Bagging', 'GBR', 'RF']\n",
    "# create a list of colors for each bar\n",
    "colors = ['red', 'green', 'blue', 'yellow', 'orange', 'purple']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# plot the bars with the corresponding colors\n",
    "plt.bar(models, np.array(mse)*10000000, width=0.5, color=colors)\n",
    "# add a colorbar to show the color scale\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = ['MLP', 'LSTM', 'Linear', 'Bagging', 'GBR', 'RF']\n",
    "# create a list of colors for each bar\n",
    "colors = ['red', 'green', 'blue', 'yellow', 'orange', 'purple']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# plot the bars with the corresponding colors\n",
    "plt.bar(models, r2score, width=0.5, color=colors)\n",
    "# add a colorbar to show the color scale\n",
    "\n",
    "plt.ylabel('R2 score')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'R2-score']\n",
    "all_value_metrics = np.array([mse, rmse, mae, r2score])\n",
    "all_value_metrics = all_value_metrics.T\n",
    "# plot a table with the metrics as columns and model as rows\n",
    "table = plt.table(cellText=np.round(all_value_metrics, 5), rowLabels=models, colLabels=metrics, loc='center')\n",
    "#i want to set in bolds some number\n",
    "for i in range(len(all_value_metrics)):\n",
    "  for j in range(len(all_value_metrics[0])):\n",
    "    if all_value_metrics[i][j] == np.min(all_value_metrics[:, j]) and j != 3:\n",
    "      table[(i+1, j)].set_text_props(fontproperties=FontProperties(weight='bold'))\n",
    "    elif all_value_metrics[i][j] == np.max(all_value_metrics[:, j]) and j == 3:\n",
    "      table[(i+1, j)].set_text_props(fontproperties=FontProperties(weight='bold'))\n",
    "\n",
    "\n",
    "table.set_fontsize(14)\n",
    "table.scale(1, 3)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.savefig('metrics2.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
