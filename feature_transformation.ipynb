{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering and Encoding\n",
    "**In this file, we will handle the cases in which the features values ​​are null or equal to 0. Next, we will do some transformation to rescale the features that have very different scales**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:35.243217600Z",
     "start_time": "2023-05-19T15:49:35.241001800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[('spark.app.id', 'local-1684493648751'),\n ('spark.executor.memory', '15G'),\n ('spark.sql.warehouse.dir',\n  'file:/C:/Users/leona/PycharmProjects/BDC_project/spark-warehouse'),\n ('spark.executor.id', 'driver'),\n ('spark.driver.memory', '50G'),\n ('spark.executor.cores', '10'),\n ('spark.app.name', 'PySparkProject'),\n ('spark.app.submitTime', '1684493647981'),\n ('spark.driver.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.ui.port', '4050'),\n ('spark.driver.maxResultSize', '40G'),\n ('spark.app.startTime', '1684493648140'),\n ('spark.rdd.compress', 'True'),\n ('spark.serializer.objectStreamReset', '100'),\n ('spark.master', 'local[*]'),\n ('spark.submit.pyFiles', ''),\n ('spark.submit.deployMode', 'client'),\n ('spark.driver.host', 'rig.tail9f86a.ts.net.'),\n ('spark.ui.showConsoleProgress', 'true'),\n ('spark.driver.port', '64470'),\n ('spark.executor.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the session\n",
    "conf = SparkConf(). \\\n",
    "    set('spark.ui.port', \"4050\"). \\\n",
    "    set('spark.executor.memory', '15G'). \\\n",
    "    set('spark.driver.memory', '50G'). \\\n",
    "    set('spark.driver.maxResultSize', '40G'). \\\n",
    "    setAppName(\"PySparkProject\"). \\\n",
    "    set('spark.executor.cores', \"10\"). \\\n",
    "    setMaster(\"local[*]\")\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc._conf.getAll()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:36.084645600Z",
     "start_time": "2023-05-19T15:49:36.076133600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# open data.csv as pyspark dataframe\n",
    "df = spark.read.csv('dataset.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:36.829615700Z",
     "start_time": "2023-05-19T15:49:36.565318Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The features that we have to manage are:\n",
    "- last valuation (13,45 % null --> from null to 0)\n",
    "- sub position (8,19 % null --> position)\n",
    "- age (0,04 % null --> delete examples)\n",
    "- date_birth (0,04 % null --> delete examples)\n",
    "- height (some values are 0 --> average height)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# the null values in the column last_valuation must be replaced with 0\n",
    "df = df.fillna({'last_valuation': 0})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:38.834157500Z",
     "start_time": "2023-05-19T15:49:38.824631700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# the null values in the column last_position must be replaced with the value in the column position\n",
    "df = df.withColumn(\"sub_position\", coalesce(col(\"sub_position\"), col(\"position\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:39.720907Z",
     "start_time": "2023-05-19T15:49:39.712331200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# drop instances in which the column age or date_of_birth are null\n",
    "df = df.dropna(subset=('age', 'date_birth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:39.874121Z",
     "start_time": "2023-05-19T15:49:39.866953100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# filter the dataframe to keep only the rows in which the column height is not 0\n",
    "filtered_df = df.filter(col(\"height\") != 0)\n",
    "\n",
    "# average height of filtered_df\n",
    "average_height = filtered_df.selectExpr(\"avg(height) as height_average\").first()[\"height_average\"]\n",
    "\n",
    "# replace the value 0 in the column height with the mean of the column\n",
    "df = df.withColumn(\"height\", when(col(\"height\") == 0, average_height).otherwise(col(\"height\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:40.201804400Z",
     "start_time": "2023-05-19T15:49:40.046351700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "#trasform the column height, last_valuation and age in integer\n",
    "df = df.withColumn(\"height\", df[\"height\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"last_valuation\", df[\"last_valuation\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"age\", df[\"age\"].cast(IntegerType()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:40.642949800Z",
     "start_time": "2023-05-19T15:49:40.619435500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "#transform the column competitions_id and clubs_id in string\n",
    "df = df.withColumn(\"competitions_id\", df[\"competitions_id\"].cast(StringType()))\n",
    "df = df.withColumn(\"clubs_id\", df[\"clubs_id\"].cast(StringType()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:54:11.610605Z",
     "start_time": "2023-05-19T15:54:11.560491300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Encoding**\n",
    "\n",
    "We have to execute the mapping for:\n",
    "- player_id (it will be divider for 100k)\n",
    "- date_c in timestamp\n",
    "- current_club_id\n",
    "- citizenship\n",
    "- position\n",
    "- sub_position\n",
    "- competitions_id\n",
    "- clubs_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "#drop useless features\n",
    "df = df.drop(\"name\", \"date_birth\", \"games_played_club\", \"games_won_club\", \"games_draw_club\", \"games_lost_club\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:49:46.853052200Z",
     "start_time": "2023-05-19T15:49:46.847339900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# convert df in pandas dataframe\n",
    "df_pandas = df.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:54:18.201561200Z",
     "start_time": "2023-05-19T15:54:16.625456600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id      date_v  market_value  age  current_club_id  height   \n",
      "0         26  2015-02-04       3000000   34               16     190  \\\n",
      "1         26  2015-07-01       2000000   34               16     190   \n",
      "2         26  2015-10-16       1000000   35               16     190   \n",
      "3         26  2016-02-15       1000000   35               16     190   \n",
      "4         26  2016-07-22       1000000   35               16     190   \n",
      "\n",
      "  citizenship    position sub_position            competitions_id  ...   \n",
      "0     Germany  Goalkeeper   Goalkeeper               ['CL', 'L1']  ...  \\\n",
      "1     Germany  Goalkeeper   Goalkeeper               ['CL', 'L1']  ...   \n",
      "2     Germany  Goalkeeper   Goalkeeper  ['CL', 'ELQ', 'L1', 'EL']  ...   \n",
      "3     Germany  Goalkeeper   Goalkeeper  ['CL', 'ELQ', 'L1', 'EL']  ...   \n",
      "4     Germany  Goalkeeper   Goalkeeper        ['ELQ', 'L1', 'EL']  ...   \n",
      "\n",
      "  minutes_played  red_cards  yellow_cards  last_valuation  appearances   \n",
      "0           1620          0             0               0           18  \\\n",
      "1           2880          0             0         3000000           32   \n",
      "2           2610          0             0         2000000           29   \n",
      "3           1800          0             0         1000000           20   \n",
      "4           1260          0             1         1000000           14   \n",
      "\n",
      "   games_won_pl  games_draw_pl  games_lost_pl  winning_rate_pl   \n",
      "0             7              3              8              1.3  \\\n",
      "1            14              5             13              1.5   \n",
      "2            14              5             10              1.6   \n",
      "3            11              3              6              1.8   \n",
      "4             9              2              3              2.1   \n",
      "\n",
      "   winning_rate_club  \n",
      "0                1.7  \n",
      "1                1.6  \n",
      "2                1.8  \n",
      "3                2.1  \n",
      "4                2.3  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_pandas.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:54:18.202561100Z",
     "start_time": "2023-05-19T15:54:18.187360400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "df_pandas[\"date_v\"] = pd.to_datetime(df_pandas[\"date_v\"])\n",
    "\n",
    "#we map the categorical values in their indexes values to have numerical values\n",
    "df_pandas['position'] = df_pandas['position'].astype('category')\n",
    "df_pandas['position'] = df_pandas['position'].cat.codes\n",
    "\n",
    "df_pandas['sub_position'] = df_pandas['sub_position'].astype('category')\n",
    "df_pandas['sub_position'] = df_pandas['sub_position'].cat.codes\n",
    "\n",
    "df_pandas['citizenship'] = df_pandas['citizenship'].astype('category')\n",
    "df_pandas['citizenship'] = df_pandas['citizenship'].cat.codes\n",
    "\n",
    "df_pandas['current_club_id'] = df_pandas['current_club_id'].astype('category')\n",
    "df_pandas['current_club_id'] = df_pandas['current_club_id'].cat.codes\n",
    "\n",
    "df_pandas['competitions_id'] = df_pandas['competitions_id'].astype('category')\n",
    "df_pandas['competitions_id'] = df_pandas['competitions_id'].cat.codes\n",
    "\n",
    "df_pandas['clubs_id'] = df_pandas['clubs_id'].astype('category')\n",
    "df_pandas['clubs_id'] = df_pandas['clubs_id'].cat.codes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:55:35.685130200Z",
     "start_time": "2023-05-19T15:55:35.579737700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135878 entries, 0 to 135877\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   player_id          135878 non-null  int32         \n",
      " 1   date_v             135878 non-null  datetime64[ns]\n",
      " 2   market_value       135878 non-null  int32         \n",
      " 3   age                135878 non-null  int32         \n",
      " 4   current_club_id    135878 non-null  int16         \n",
      " 5   height             135878 non-null  int32         \n",
      " 6   citizenship        135878 non-null  int16         \n",
      " 7   position           135878 non-null  int8          \n",
      " 8   sub_position       135878 non-null  int8          \n",
      " 9   assists            135878 non-null  int32         \n",
      " 10  goals              135878 non-null  int32         \n",
      " 11  minutes_played     135878 non-null  int32         \n",
      " 12  red_cards          135878 non-null  int32         \n",
      " 13  yellow_cards       135878 non-null  int32         \n",
      " 14  last_valuation     135878 non-null  int32         \n",
      " 15  appearances        135878 non-null  int32         \n",
      " 16  games_won_pl       135878 non-null  int32         \n",
      " 17  games_draw_pl      135878 non-null  int32         \n",
      " 18  games_lost_pl      135878 non-null  int32         \n",
      " 19  winning_rate_pl    135878 non-null  float64       \n",
      " 20  winning_rate_club  135878 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int16(2), int32(14), int8(2)\n",
      "memory usage: 11.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_pandas.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T10:54:38.000934700Z",
     "start_time": "2023-05-19T10:54:37.989854Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformation\n",
    "We apply zscore to every column except for age, last_valuation, market_value and these to be encoded\n",
    "We apply min-max scaling to age because with zscore the values would be all Nan\n",
    "We rescale market_value (labels) and last_valuation through dividing to the maximum/2 (1e+8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "df_pandas['year_v'] = pd.to_datetime(df_pandas['date_v']).dt.year\n",
    "df_pandas['month_v'] = pd.to_datetime(df_pandas['date_v']).dt.month\n",
    "df_pandas['day_v'] = pd.to_datetime(df_pandas['date_v']).dt.day\n",
    "\n",
    "df_pandas = df_pandas.drop(\"date_v\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:57:10.451139600Z",
     "start_time": "2023-05-19T15:57:10.396988100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "to_encoding = df_pandas[['citizenship', 'current_club_id', 'position', 'sub_position', 'competitions_id', 'clubs_id']]\n",
    "df_pandas = df_pandas.drop(['citizenship', 'current_club_id', 'position', 'sub_position', 'competitions_id', 'clubs_id'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:58:08.468799500Z",
     "start_time": "2023-05-19T15:58:08.464551200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the scaling factor of market_valuea is: 10000000.0\n",
      "the scaling factor of last_valuations is: 10000000.0\n"
     ]
    }
   ],
   "source": [
    "#min-max scaling for age\n",
    "scaler = MinMaxScaler()\n",
    "age_minmax = scaler.fit_transform(df_pandas[['age']])\n",
    "\n",
    "#rescaling market_value\n",
    "scaling_factor_market_value = np.max(df_pandas['market_value'].to_numpy()) / 20\n",
    "print(\"the scaling factor of market_valuea is: {}\".format(scaling_factor_market_value))\n",
    "market_val_scaled = df_pandas['market_value'] / scaling_factor_market_value\n",
    "\n",
    "#rescaling\n",
    "scaling_factor_valuation = np.max(df_pandas['last_valuation'].to_numpy()) / 20\n",
    "print(\"the scaling factor of last_valuations is: {}\".format(scaling_factor_valuation))\n",
    "last_val_scaled = df_pandas['last_valuation'] / scaling_factor_valuation\n",
    "\n",
    "df_zscore = df_pandas.apply(zscore, axis=0)\n",
    "\n",
    "df_zscore['market_value'] = market_val_scaled\n",
    "df_zscore['age'] = age_minmax\n",
    "df_zscore['last_valuation'] = last_val_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:58:12.754795400Z",
     "start_time": "2023-05-19T15:58:12.704077600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135878 entries, 0 to 135877\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   player_id          135878 non-null  float64\n",
      " 1   market_value       135878 non-null  float64\n",
      " 2   age                135878 non-null  float64\n",
      " 3   height             135878 non-null  float64\n",
      " 4   assists            135878 non-null  float64\n",
      " 5   goals              135878 non-null  float64\n",
      " 6   minutes_played     135878 non-null  float64\n",
      " 7   red_cards          135878 non-null  float64\n",
      " 8   yellow_cards       135878 non-null  float64\n",
      " 9   last_valuation     135878 non-null  float64\n",
      " 10  appearances        135878 non-null  float64\n",
      " 11  games_won_pl       135878 non-null  float64\n",
      " 12  games_draw_pl      135878 non-null  float64\n",
      " 13  games_lost_pl      135878 non-null  float64\n",
      " 14  winning_rate_pl    135878 non-null  float64\n",
      " 15  winning_rate_club  135878 non-null  float64\n",
      " 16  year_v             135878 non-null  float64\n",
      " 17  month_v            135878 non-null  float64\n",
      " 18  day_v              135878 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 19.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_zscore.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:58:15.099955Z",
     "start_time": "2023-05-19T15:58:15.091962100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "df_zscore = pd.concat([df_zscore, to_encoding], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:58:17.354792700Z",
     "start_time": "2023-05-19T15:58:17.349276300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "#i wanto to save the dataframe\n",
    "df_zscore.to_csv(\"dataset_normalized.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T15:58:19.213060900Z",
     "start_time": "2023-05-19T15:58:17.643633400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
