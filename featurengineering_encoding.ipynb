{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Encoding\n",
    "**In this file, we will handle the cases in which the features values ​​are null or equal to 0. Next, some features need to be encoded to prepare the dataset for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:38.074279800Z",
     "start_time": "2023-05-13T12:03:37.559505500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BinaryType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:39.995943900Z",
     "start_time": "2023-05-13T12:03:38.076273400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('spark.executor.memory', '15G'),\n ('spark.app.submitTime', '1683979419185'),\n ('spark.app.id', 'local-1683979419759'),\n ('spark.executor.id', 'driver'),\n ('spark.driver.memory', '50G'),\n ('spark.executor.cores', '10'),\n ('spark.app.name', 'PySparkProject'),\n ('spark.driver.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.ui.port', '4050'),\n ('spark.driver.maxResultSize', '40G'),\n ('spark.rdd.compress', 'True'),\n ('spark.app.startTime', '1683979419256'),\n ('spark.serializer.objectStreamReset', '100'),\n ('spark.master', 'local[*]'),\n ('spark.driver.port', '58465'),\n ('spark.submit.pyFiles', ''),\n ('spark.submit.deployMode', 'client'),\n ('spark.driver.host', 'rig.tail9f86a.ts.net.'),\n ('spark.ui.showConsoleProgress', 'true'),\n ('spark.executor.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the session\n",
    "conf = SparkConf(). \\\n",
    "    set('spark.ui.port', \"4050\"). \\\n",
    "    set('spark.executor.memory', '15G'). \\\n",
    "    set('spark.driver.memory', '50G'). \\\n",
    "    set('spark.driver.maxResultSize', '40G'). \\\n",
    "    setAppName(\"PySparkProject\"). \\\n",
    "    set('spark.executor.cores', \"10\"). \\\n",
    "    setMaster(\"local[*]\")\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:42.527411600Z",
     "start_time": "2023-05-13T12:03:39.995943900Z"
    }
   },
   "outputs": [],
   "source": [
    "# open data.csv as pyspark dataframe\n",
    "df = spark.read.csv('data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:42.559311800Z",
     "start_time": "2023-05-13T12:03:42.527411600Z"
    }
   },
   "outputs": [],
   "source": [
    "# the null values in the column last_valuation must be replaced with 0\n",
    "df = df.fillna({'last_valuation': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:42.778968400Z",
     "start_time": "2023-05-13T12:03:42.560308300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+------------------+----------+----+---------------+------+-----------+----------+------------+--------------------+--------+-------+-----+--------------+---------+------------+--------------+-----------+------------+-------------+-------------+---------------+-----------------+--------------+---------------+---------------+-----------------+\n",
      "|player_id|    date_v|market_value|              name|date_birth| age|current_club_id|height|citizenship|  position|sub_position|     competitions_id|clubs_id|assists|goals|minutes_played|red_cards|yellow_cards|last_valuation|appearances|games_won_pl|games_draw_pl|games_lost_pl|winning_rate_pl|games_played_club|games_won_club|games_draw_club|games_lost_club|winning_rate_club|\n",
      "+---------+----------+------------+------------------+----------+----+---------------+------+-----------+----------+------------+--------------------+--------+-------+-----+--------------+---------+------------+--------------+-----------+------------+-------------+-------------+---------------+-----------------+--------------+---------------+---------------+-----------------+\n",
      "|       26|2015-02-04|     3000000|Roman Weidenfeller|1980-08-06|34.0|             16|   190|    Germany|Goalkeeper|        null|        ['CL', 'L1']|    [16]|      0|    0|          1620|        0|           0|           0.0|         18|           7|            3|            8|            1.3|               50|            26|              7|             17|              1.7|\n",
      "|       26|2015-07-01|     2000000|Roman Weidenfeller|1980-08-06|34.0|             16|   190|    Germany|Goalkeeper|        null|        ['CL', 'L1']|    [16]|      0|    0|          2880|        0|           0|     3000000.0|         32|          14|            5|           13|            1.5|               49|            23|              8|             18|              1.6|\n",
      "|       26|2015-10-16|     1000000|Roman Weidenfeller|1980-08-06|35.0|             16|   190|    Germany|Goalkeeper|        null|['CL', 'ELQ', 'L1...|    [16]|      0|    0|          2610|        0|           0|     2000000.0|         29|          14|            5|           10|            1.6|               54|            29|             10|             15|              1.8|\n",
      "|       26|2016-02-15|     1000000|Roman Weidenfeller|1980-08-06|35.0|             16|   190|    Germany|Goalkeeper|        null|['CL', 'ELQ', 'L1...|    [16]|      0|    0|          1800|        0|           0|     1000000.0|         20|          11|            3|            6|            1.8|               54|            36|              7|             11|              2.1|\n",
      "|       26|2016-07-22|     1000000|Roman Weidenfeller|1980-08-06|35.0|             16|   190|    Germany|Goalkeeper|        null| ['ELQ', 'L1', 'EL']|    [16]|      0|    0|          1260|        0|           1|     1000000.0|         14|           9|            2|            3|            2.1|               56|            40|              8|              8|              2.3|\n",
      "+---------+----------+------------+------------------+----------+----+---------------+------+-----------+----------+------------+--------------------+--------+-------+-----+--------------+---------+------------+--------------+-----------+------------+-------------+-------------+---------------+-----------------+--------------+---------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the first 5 rows of the dataframe with sub_position null\n",
    "df.filter(df.sub_position.isNull()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:42.809865900Z",
     "start_time": "2023-05-13T12:03:42.779964900Z"
    }
   },
   "outputs": [],
   "source": [
    "# the null values in the column last_position must be replaced with the value in the column position\n",
    "df = df.withColumn(\"sub_position\", coalesce(col(\"sub_position\"), col(\"position\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:42.825811700Z",
     "start_time": "2023-05-13T12:03:42.810861600Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop instances in which the column age or date_of_birth are null\n",
    "df = df.dropna(subset=('age', 'date_birth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "135878"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.count())\n",
    "df.dropDuplicates([\"date_v\", \"player_id\"])\n",
    "df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T12:03:43.366004200Z",
     "start_time": "2023-05-13T12:03:42.825811700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:06:36.720791200Z",
     "start_time": "2023-05-13T12:06:36.587694500Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter the dataframe to keep only the rows in which the column height is not 0\n",
    "filtered_df = df.filter(col(\"age\") != 0)\n",
    "\n",
    "# average height of filtered_df\n",
    "average_height = filtered_df.selectExpr(\"avg(height) as height_average\").first()[\"height_average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:06:37.488892100Z",
     "start_time": "2023-05-13T12:06:37.458439400Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace the value 0 in the column height with the mean of the column \n",
    "df = df.withColumn(\"height\", when(col(\"height\") == 0, average_height).otherwise(col(\"height\")))\n",
    "# TODO fare in modo che dopo la virgola ci sia 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that we have to manage are: \n",
    "- last valuation (13,45 % null --> from null to 0)\n",
    "- sub position (8,19 % null --> position)\n",
    "- age (0,04 % null --> delete examples)\n",
    "- date_birth (0,04 % null)\n",
    "- height (some values are 0 --> average height)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We transform the column competitions id and clubs id, that are array of strings in a single binary value using label binarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:06:49.040781800Z",
     "start_time": "2023-05-13T12:06:48.987959100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert clubs id and competitions id from list to string\n",
    "df = df.withColumn(\"competitions_id\", split(expr(\"substring(competitions_id, 2, length(competitions_id)-2)\"), \", \"))\n",
    "df = df.withColumn(\"clubs_id\", split(expr(\"substring(clubs_id, 2, length(clubs_id)-2)\"), \", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:06:55.750175700Z",
     "start_time": "2023-05-13T12:06:53.852516Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert df in pandas dataframe\n",
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T12:07:50.863643700Z",
     "start_time": "2023-05-13T12:07:39.918186800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_16884\\3066461306.py:2: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  dummies = pd.get_dummies(df_pandas[\"competitions_id\"].apply(pd.Series).stack()).sum(level=0)\n"
     ]
    }
   ],
   "source": [
    "# apply pd.get_dummies to the column of arrays\n",
    "dummies = pd.get_dummies(df_pandas[\"competitions_id\"].apply(pd.Series).stack()).sum(level=0)\n",
    "# concatenate the dummy variables into a single string\n",
    "dummies[\"comp_string\"] = dummies.apply(lambda x: \"\".join(x.astype(str)), axis=1)\n",
    "# join the dummies dataframe with the original dataframe\n",
    "df_pandas = df_pandas.join(dummies[\"comp_string\"])\n",
    "#df_pandas = df_pandas.drop(\"competitions_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T12:08:10.993249900Z",
     "start_time": "2023-05-13T12:07:50.864639200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_16884\\2976684545.py:2: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  dummies = pd.get_dummies(df_pandas[\"clubs_id\"].apply(pd.Series).stack()).sum(level=0)\n"
     ]
    }
   ],
   "source": [
    "# apply pd.get_dummies to the column of arrays\n",
    "dummies = pd.get_dummies(df_pandas[\"clubs_id\"].apply(pd.Series).stack()).sum(level=0)\n",
    "# concatenate the dummy variables into a single string\n",
    "dummies[\"club_string\"] = dummies.apply(lambda x: \"\".join(x.astype(str)), axis=1)\n",
    "# join the dummies dataframe with the original dataframe\n",
    "df_pandas = df_pandas.join(dummies[\"club_string\"])\n",
    "#df_pandas = df_pandas.drop(\"club_str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T12:08:11.056054300Z",
     "start_time": "2023-05-13T12:08:10.994248200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pandas = df_pandas.drop([\"name\", \"date_birth\", \"games_played_club\", \"games_won_club\", \"games_draw_club\", \"games_lost_club\", \"competitions_id\", \"clubs_id\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "prima fare label binarization e poi nn.Encoding pytorch\n",
    "\n",
    "da encodare:\n",
    "  - date_v in timestemp\n",
    "  - current_club_id\n",
    "    - citizenship\n",
    "        - position\n",
    "- sub_position\n",
    "- comp_string\n",
    "- club_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135878 entries, 0 to 135877\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   player_id          135878 non-null  int32  \n",
      " 1   date_v             135878 non-null  object \n",
      " 2   market_value       135878 non-null  int32  \n",
      " 3   age                135878 non-null  float64\n",
      " 4   current_club_id    135878 non-null  int32  \n",
      " 5   height             135878 non-null  float64\n",
      " 6   citizenship        135878 non-null  object \n",
      " 7   position           135878 non-null  object \n",
      " 8   sub_position       135878 non-null  object \n",
      " 9   assists            135878 non-null  int32  \n",
      " 10  goals              135878 non-null  int32  \n",
      " 11  minutes_played     135878 non-null  int32  \n",
      " 12  red_cards          135878 non-null  int32  \n",
      " 13  yellow_cards       135878 non-null  int32  \n",
      " 14  last_valuation     135878 non-null  float64\n",
      " 15  appearances        135878 non-null  int32  \n",
      " 16  games_won_pl       135878 non-null  int32  \n",
      " 17  games_draw_pl      135878 non-null  int32  \n",
      " 18  games_lost_pl      135878 non-null  int32  \n",
      " 19  winning_rate_pl    135878 non-null  float64\n",
      " 20  winning_rate_club  135878 non-null  float64\n",
      " 21  comp_string        135878 non-null  object \n",
      " 22  club_string        135878 non-null  object \n",
      "dtypes: float64(5), int32(12), object(6)\n",
      "memory usage: 17.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pandas.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T12:08:11.117424900Z",
     "start_time": "2023-05-13T12:08:11.057050600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:08:11.178544Z",
     "start_time": "2023-05-13T12:08:11.118422400Z"
    }
   },
   "outputs": [],
   "source": [
    "# divided the column player_id for 1 million\n",
    "df_pandas[\"player_id\"] = df_pandas[\"player_id\"].apply(lambda x: x/100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T12:08:11.195265500Z",
     "start_time": "2023-05-13T12:08:11.149642400Z"
    }
   },
   "outputs": [],
   "source": [
    "# copia df_pandas in df_c\n",
    "df_c = df_pandas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop name, date_birth     - games_played_club     - games_won_club     - games_draw_club     - games_lost_club\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
